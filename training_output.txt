ğŸ¯ Unified AQI Model Training Pipeline
ğŸ• Pipeline started at: 2025-12-11 02:31:17 PKT
======================================================================

============================================================
ğŸš€ Training RandomForest Model
â° Started at: 2025-12-11 02:31:20 PKT
============================================================
ğŸš€ Starting AQI Random Forest Training Pipeline...
============================================================
ğŸ“ Output directory: randomforest_additional/12_11_2025_0231_pkt

ğŸ“Š Step 1: Fetching data from Hopsworks...
ğŸ”— Connecting to Hopsworks project: anassale
2025-12-11 02:31:20,610 INFO: Initializing external client
2025-12-11 02:31:20,610 INFO: Base URL: https://c.app.hopsworks.ai:443
2025-12-11 02:31:21,351 INFO: Python Engine initialized.

Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1263764
âœ… Successfully connected to Hopsworks
âœ… Latest version of karachifeatures10: 1
ğŸ“¥ Retrieving features from: karachifeatures10 (v1)
ğŸ“‹ Retrieving all records...
Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   2025-12-11 02:32:05,532 ERROR: [Errno 255] Opening HDFS file '/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties' failed. Detail: [errno 255] Unknown error 255. Detail: Python exception: Traceback (most recent call last):
  File "/usr/src/app/src/server.py", line 142, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 166, in wrapper
    result = func(instance, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 196, in do_get
    return self._read_query(context, path, command)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 123, in wrapper
    return func(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 131, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 227, in _read_query
    result_batches = self.hudi_query_engine.read_query(query_obj)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/hudi_query_engine.py", line 63, in read_query
    hudi_featuregroups_paths[full_featuregroup_name] = self.hudi_hops_client.get_featuregroup_parquet_paths(
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/hudi_hopsfs_client.py", line 55, in get_featuregroup_parquet_paths
    partition_keys = self._get_partition_keys_from_metadata(featuregroup_absolute_path)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/hudi_hopsfs_client.py", line 185, in _get_partition_keys_from_metadata
    with self.hopsfs.open(featuregroup_hoodie_properties_path.as_posix(), "rt") as f:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/fsspec/spec.py", line 1139, in open
    self.open(
  File "/opt/venv/lib/python3.11/site-packages/fsspec/spec.py", line 1151, in open
    f = self._open(
        ^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/fsspec/implementations/arrow.py", line 22, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/fsspec/implementations/arrow.py", line 178, in _open
    stream = method(path, **_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "pyarrow/_fs.pyx", line 789, in pyarrow._fs.FileSystem.open_input_file
  File "pyarrow/error.pxi", line 155, in pyarrow.lib.pyarrow_internal_check_status
  File "pyarrow/error.pxi", line 92, in pyarrow.lib.check_status
OSError: [Errno 255] Opening HDFS file '/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties' failed. Detail: [errno 255] Unknown error 255

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "pyarrow/_flight.pyx", line 2255, in pyarrow._flight._do_get
  File "/usr/src/app/src/server.py", line 145, in wrapper
    raise FlyingDuckException(str(e)) from e
utils.exceptions.FlyingDuckException: [Errno 255] Opening HDFS file '/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties' failed. Detail: [errno 255] Unknown error 255
. gRPC client debug context: UNKNOWN:Error received from peer ipv4:51.79.26.27:5005 {grpc_message:"[Errno 255] Opening HDFS file \'/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties\' failed. Detail: [errno 255] Unknown error 255. Detail: Python exception: Traceback (most recent call last):\n  File \"/usr/src/app/src/server.py\", line 142, in wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 166, in wrapper\n    result = func(instance, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 196, in do_get\n    return self._read_query(context, path, command)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 123, in wrapper\n    return func(instance, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 131, in wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 227, in _read_query\n    result_batches = self.hudi_query_engine.read_query(query_obj)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/hudi_query_engine.py\", line 63, in read_query\n    hudi_featuregroups_paths[full_featuregroup_name] = self.hudi_hops_client.get_featuregroup_parquet_paths(\n                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/hudi_hopsfs_client.py\", line 55, in get_featuregroup_parquet_paths\n    partition_keys = self._get_partition_keys_from_metadata(featuregroup_absolute_path)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/hudi_hopsfs_client.py\", line 185, in _get_partition_keys_from_metadata\n    with self.hopsfs.open(featuregroup_hoodie_properties_path.as_posix(), \"rt\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/venv/lib/python3.11/site-packages/fsspec/spec.py\", line 1139, in open\n    self.open(\n  File \"/opt/venv/lib/python3.11/site-packages/fsspec/spec.py\", line 1151, in open\n    f = self._open(\n        ^^^^^^^^^^^\n  File \"/opt/venv/lib/python3.11/site-packages/fsspec/implementations/arrow.py\", line 22, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/venv/lib/python3.11/site-packages/fsspec/implementations/arrow.py\", line 178, in _open\n    stream = method(path, **_kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"pyarrow/_fs.pyx\", line 789, in pyarrow._fs.FileSystem.open_input_file\n  File \"pyarrow/error.pxi\", line 155, in pyarrow.lib.pyarrow_internal_check_status\n  File \"pyarrow/error.pxi\", line 92, in pyarrow.lib.check_status\nOSError: [Errno 255] Opening HDFS file \'/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties\' failed. Detail: [errno 255] Unknown error 255\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"pyarrow/_flight.pyx\", line 2255, in pyarrow._flight._do_get\n  File \"/usr/src/app/src/server.py\", line 145, in wrapper\n    raise FlyingDuckException(str(e)) from e\nutils.exceptions.FlyingDuckException: [Errno 255] Opening HDFS file \'/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties\' failed. Detail: [errno 255] Unknown error 255\n", grpc_status:2, created_time:"2025-12-11T02:32:05.532274913+05:00"}. Client context: IOError: Server never sent a data message. Detail: Internal
Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/hsfs/core/arrow_flight_client.py", line 394, in afs_error_handler_wrapper
    return func(instance, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/hsfs/core/arrow_flight_client.py", line 459, in read_query
    return self._get_dataset(
           ^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/retrying.py", line 55, in wrapped_f
    return Retrying(*dargs, **dkw).call(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/retrying.py", line 279, in call
    return attempt.get(self._wrap_exception)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/retrying.py", line 326, in get
    raise exc.with_traceback(tb)
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/retrying.py", line 273, in call
    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)
                      ^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/hsfs/core/arrow_flight_client.py", line 445, in _get_dataset
    reader = self._connection.do_get(info.endpoints[0].ticket, options)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "pyarrow/_flight.pyx", line 1745, in pyarrow._flight.FlightClient.do_get
  File "pyarrow/_flight.pyx", line 58, in pyarrow._flight.check_flight_status
pyarrow._flight.FlightServerError: [Errno 255] Opening HDFS file '/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties' failed. Detail: [errno 255] Unknown error 255. Detail: Python exception: Traceback (most recent call last):
  File "/usr/src/app/src/server.py", line 142, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 166, in wrapper
    result = func(instance, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 196, in do_get
    return self._read_query(context, path, command)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 123, in wrapper
    return func(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 131, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 227, in _read_query
    result_batches = self.hudi_query_engine.read_query(query_obj)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/hudi_query_engine.py", line 63, in read_query
    hudi_featuregroups_paths[full_featuregroup_name] = self.hudi_hops_client.get_featuregroup_parquet_paths(
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/hudi_hopsfs_client.py", line 55, in get_featuregroup_parquet_paths
    partition_keys = self._get_partition_keys_from_metadata(featuregroup_absolute_path)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/hudi_hopsfs_client.py", line 185, in _get_partition_keys_from_metadata
    with self.hopsfs.open(featuregroup_hoodie_properties_path.as_posix(), "rt") as f:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/fsspec/spec.py", line 1139, in open
    self.open(
  File "/opt/venv/lib/python3.11/site-packages/fsspec/spec.py", line 1151, in open
    f = self._open(
        ^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/fsspec/implementations/arrow.py", line 22, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/fsspec/implementations/arrow.py", line 178, in _open
    stream = method(path, **_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "pyarrow/_fs.pyx", line 789, in pyarrow._fs.FileSystem.open_input_file
  File "pyarrow/error.pxi", line 155, in pyarrow.lib.pyarrow_internal_check_status
  File "pyarrow/error.pxi", line 92, in pyarrow.lib.check_status
OSError: [Errno 255] Opening HDFS file '/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties' failed. Detail: [errno 255] Unknown error 255

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "pyarrow/_flight.pyx", line 2255, in pyarrow._flight._do_get
  File "/usr/src/app/src/server.py", line 145, in wrapper
    raise FlyingDuckException(str(e)) from e
utils.exceptions.FlyingDuckException: [Errno 255] Opening HDFS file '/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties' failed. Detail: [errno 255] Unknown error 255
. gRPC client debug context: UNKNOWN:Error received from peer ipv4:51.79.26.27:5005 {grpc_message:"[Errno 255] Opening HDFS file \'/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties\' failed. Detail: [errno 255] Unknown error 255. Detail: Python exception: Traceback (most recent call last):\n  File \"/usr/src/app/src/server.py\", line 142, in wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 166, in wrapper\n    result = func(instance, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 196, in do_get\n    return self._read_query(context, path, command)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 123, in wrapper\n    return func(instance, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 131, in wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 227, in _read_query\n    result_batches = self.hudi_query_engine.read_query(query_obj)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/hudi_query_engine.py\", line 63, in read_query\n    hudi_featuregroups_paths[full_featuregroup_name] = self.hudi_hops_client.get_featuregroup_parquet_paths(\n                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/hudi_hopsfs_client.py\", line 55, in get_featuregroup_parquet_paths\n    partition_keys = self._get_partition_keys_from_metadata(featuregroup_absolute_path)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/hudi_hopsfs_client.py\", line 185, in _get_partition_keys_from_metadata\n    with self.hopsfs.open(featuregroup_hoodie_properties_path.as_posix(), \"rt\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/venv/lib/python3.11/site-packages/fsspec/spec.py\", line 1139, in open\n    self.open(\n  File \"/opt/venv/lib/python3.11/site-packages/fsspec/spec.py\", line 1151, in open\n    f = self._open(\n        ^^^^^^^^^^^\n  File \"/opt/venv/lib/python3.11/site-packages/fsspec/implementations/arrow.py\", line 22, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/venv/lib/python3.11/site-packages/fsspec/implementations/arrow.py\", line 178, in _open\n    stream = method(path, **_kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"pyarrow/_fs.pyx\", line 789, in pyarrow._fs.FileSystem.open_input_file\n  File \"pyarrow/error.pxi\", line 155, in pyarrow.lib.pyarrow_internal_check_status\n  File \"pyarrow/error.pxi\", line 92, in pyarrow.lib.check_status\nOSError: [Errno 255] Opening HDFS file \'/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties\' failed. Detail: [errno 255] Unknown error 255\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"pyarrow/_flight.pyx\", line 2255, in pyarrow._flight._do_get\n  File \"/usr/src/app/src/server.py\", line 145, in wrapper\n    raise FlyingDuckException(str(e)) from e\nutils.exceptions.FlyingDuckException: [Errno 255] Opening HDFS file \'/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties\' failed. Detail: [errno 255] Unknown error 255\n", grpc_status:2, created_time:"2025-12-11T02:32:05.532274913+05:00"}. Client context: IOError: Server never sent a data message. Detail: Internal
Error: Reading data from Hopsworks, using Hopsworks Feature Query Service           
âŒ Failed to retrieve features from Hopsworks: Could not read data using Hopsworks Query Service.
âš ï¸ Trying local CSV files...
ğŸ“ Loading data from local file: retrieved_karachi_aqi_features15.csv
âœ… Loaded 9704 records from retrieved_karachi_aqi_features15.csv

ğŸ”§ Step 2: Preprocessing data...
ğŸ”§ Preprocessing data...
   ğŸ§¹ Handling missing values...
   ğŸ“Š Ensuring engineered features are properly calculated...
   â• Creating lag features for pollutants...
   â• Creating lag features for pm2_5_nowcast...
   â• Creating lag features for pm10_nowcast...
   â• Creating lag features for co_ppm_8hr_avg...
   â• Creating lag features for no2_ppb...
   âœ… After preprocessing: 9699 records

ğŸ“Š Step 3: Creating time series splits...
ğŸ“Š Creating time series splits...
âš ï¸ Skipping split - insufficient training data: 4 samples
âœ… Created 4 time series splits

ğŸ¤– Step 4: Training Random Forest models...

ğŸ“ Training on split 1/4
ğŸ¤– Training Random Forest model...
âœ… Using optimized hyperparameters from Optuna
ğŸ¯ Key params: n_estimators=500, max_depth=25, min_samples_split=6
âœ… Model trained successfully
ğŸ“Š Validation RMSE: 3.6750
ğŸŒ² OOB Score: 0.9978
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 8.8534
RMSE                : 28.5152
R2                  : 0.8941
MAPE                : 0.0230
Explained Variance  : 0.8996
ğŸ† New best model found! RÂ² = 0.8941

ğŸ“ Training on split 2/4
ğŸ¤– Training Random Forest model...
âœ… Using optimized hyperparameters from Optuna
ğŸ¯ Key params: n_estimators=500, max_depth=25, min_samples_split=6
âœ… Model trained successfully
ğŸ“Š Validation RMSE: 1.5290
ğŸŒ² OOB Score: 0.9993
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 1.4041
RMSE                : 3.1414
R2                  : 0.9989
MAPE                : 0.0217
Explained Variance  : 0.9989
ğŸ† New best model found! RÂ² = 0.9989

ğŸ“ Training on split 3/4
ğŸ¤– Training Random Forest model...
âœ… Using optimized hyperparameters from Optuna
ğŸ¯ Key params: n_estimators=500, max_depth=25, min_samples_split=6
âœ… Model trained successfully
ğŸ“Š Validation RMSE: 3.2855
ğŸŒ² OOB Score: 0.9996
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 1.7683
RMSE                : 3.2475
R2                  : 0.9785
MAPE                : 0.0212
Explained Variance  : 0.9805

ğŸ“ Training on split 4/4
ğŸ¤– Training Random Forest model...
âœ… Using optimized hyperparameters from Optuna
ğŸ¯ Key params: n_estimators=500, max_depth=25, min_samples_split=6
âœ… Model trained successfully
ğŸ“Š Validation RMSE: 0.9345
ğŸŒ² OOB Score: 0.9997
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 0.5386
RMSE                : 2.0340
R2                  : 0.9984
MAPE                : 0.0217
Explained Variance  : 0.9984

ğŸ“Š Step 5: Analyzing feature importance (best model from split 2)...
ğŸ“Š Plotting feature importance...

ğŸ” Step 6: SHAP analysis...
ğŸ” Performing SHAP analysis...

ğŸ” Step 7: LIME analysis...
ğŸ” Performing LIME analysis (fast mode)...

ğŸ”® Step 8: Generating 3-day AQI forecast...
ğŸ”® Generating 3-day AQI forecast using recursive approach...
ğŸ“Š Starting forecast from: 2025-11-23 17:00:00
ğŸ¯ Forecasting 72 hours ahead...
âœ… Generated 72 hourly forecasts for 3 days
ğŸ“Š Forecast range: 183.2 - 316.3 AQI
ğŸ“ˆ Forecast average: 233.8 AQI

ğŸ”§ Step 8b: Applying bias correction...
âœ… Loaded XGBoost forecasts from 12_10_2025_0231_pkt
âœ… Loaded LightGBM forecasts from 12_10_2025_0231_pkt
ğŸ“Š Reference mean from 2 models: 149.48
ğŸ“ˆ Random Forest forecast mean: 233.78
ğŸ“Š Reference mean: 149.48
ğŸ“Š Ratio (RF/Reference): 1.56
âœ… Applied bias correction!
ğŸ“Š Correction factor: 0.639
ğŸ“Š Corrected mean: 149.48
ğŸ“Š Reduction: 84.29 AQI (36.1%)

ğŸ’¾ Step 9: Saving results...

âœ… Random Forest Training Pipeline Completed Successfully!
============================================================
ğŸ“ All results saved to: randomforest_additional/12_11_2025_0231_pkt
ğŸ¯ Best RÂ² Score: 0.9989
ğŸ“Š Best MAE: 1.4041
ğŸ“ˆ Best MAPE: 0.0217

âœ… RandomForest training completed successfully!
   Result: (RandomForestRegressor(max_depth=25, max_features=None, min_samples_leaf=2,
                      min_samples_split=6, n_estimators=500, n_jobs=-1,
                      oob_score=True, random_state=42), {'MAE': 1.4041132498502684, 'RMSE': 3.1413683149231524, 'R2': 0.9988714226266033, 'MAPE': 0.021679008665032928, 'Explained Variance': 0.9988991475499336}, 'randomforest_additional/12_11_2025_0231_pkt')

============================================================
ğŸš€ Training LightGBM Model
â° Started at: 2025-12-11 02:32:50 PKT
============================================================
ğŸš€ Starting AQI LGBM Training Pipeline
============================================================
ğŸ“ Attempting to load data from RandomForest CSV first...
âŒ No RandomForest CSV files found, trying general CSV files...
ğŸ”— Connecting to Hopsworks project: anassale
2025-12-11 02:32:50,786 INFO: Closing external client and cleaning up certificates.
Connection closed.
2025-12-11 02:32:50,788 INFO: Initializing external client
2025-12-11 02:32:50,789 INFO: Base URL: https://c.app.hopsworks.ai:443
2025-12-11 02:32:51,359 INFO: Python Engine initialized.

Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1263764
âœ… Successfully connected to Hopsworks
âœ… Latest version of karachifeatures10: 1
ğŸ“¥ Retrieving features from: karachifeatures10 (v1)
ğŸ“‹ Retrieving all records...
Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.63s) 
ğŸ”„ Sorting data by datetime for chronological order...
âœ… Successfully retrieved 10116 records
ğŸ“Š Shape: (10116, 25)
ğŸ”§ Preprocessing data...
   ğŸ§¹ Handling missing values...
   ğŸ“Š Ensuring engineered features are properly calculated...
   â• Creating lag features for pollutants...
   â• Creating lag features for pm2_5_nowcast...
   â• Creating lag features for pm10_nowcast...
   â• Creating lag features for co_ppm_8hr_avg...
   â• Creating lag features for no2_ppb...
   âœ… After preprocessing: 10111 records
ğŸ“Š Final dataset shape: (10111, 22)
ğŸ¯ Target variable range: 9.0 - 500.0
ğŸ“Š Creating time series splits...
âš ï¸ Skipping split - insufficient training data: 1 samples
âœ… Created 4 time series splits

ğŸ” Processing split 1/4
----------------------------------------
   Train: 1619 samples
   Val:   404 samples
   Test:  2022 samples
ğŸ¤– Training LightGBM model...
âœ… Using optimized hyperparameters
Training until validation scores don't improve for 50 rounds
[100]	valid_0's l2: 21.8776
[200]	valid_0's l2: 21.653
Early stopping, best iteration is:
[162]	valid_0's l2: 21.4874
âœ… Model trained with 162 iterations
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 11.1965
RMSE                : 27.8170
R2                  : 0.8999
MAPE                : 0.0360
Explained Variance  : 0.9051
ğŸ“Š Plotting feature importance...
ğŸ” Performing SHAP analysis...
ğŸ” Performing LIME analysis...
Intercept 65.28499329081367
Prediction_local [168.89328391]
Right: 179.0830428975341

ğŸ” Processing split 2/4
----------------------------------------
   Train: 3236 samples
   Val:   809 samples
   Test:  2022 samples
ğŸ¤– Training LightGBM model...
âœ… Using optimized hyperparameters
Training until validation scores don't improve for 50 rounds
[100]	valid_0's l2: 18.1494
[200]	valid_0's l2: 17.3439
[300]	valid_0's l2: 17.3028
Early stopping, best iteration is:
[282]	valid_0's l2: 17.2977
âœ… Model trained with 282 iterations
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 2.0604
RMSE                : 3.8456
R2                  : 0.9980
MAPE                : 0.0271
Explained Variance  : 0.9980
ğŸ“Š Plotting feature importance...
ğŸ” Performing SHAP analysis...

ğŸ” Processing split 3/4
----------------------------------------
   Train: 4854 samples
   Val:   1213 samples
   Test:  2022 samples
ğŸ¤– Training LightGBM model...
âœ… Using optimized hyperparameters
Training until validation scores don't improve for 50 rounds
[100]	valid_0's l2: 17.284
[200]	valid_0's l2: 15.5784
Early stopping, best iteration is:
[210]	valid_0's l2: 15.5345
âœ… Model trained with 210 iterations
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 1.7143
RMSE                : 2.9014
R2                  : 0.9849
MAPE                : 0.0362
Explained Variance  : 0.9853
ğŸ“Š Plotting feature importance...
ğŸ” Performing SHAP analysis...

ğŸ” Processing split 4/4
----------------------------------------
   Train: 6472 samples
   Val:   1617 samples
   Test:  2022 samples
ğŸ¤– Training LightGBM model...
âœ… Using optimized hyperparameters
Training until validation scores don't improve for 50 rounds
[100]	valid_0's l2: 2.04382
[200]	valid_0's l2: 1.77919
Early stopping, best iteration is:
[245]	valid_0's l2: 1.76417
âœ… Model trained with 245 iterations
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 1.3131
RMSE                : 2.6294
R2                  : 0.9977
MAPE                : 0.0308
Explained Variance  : 0.9977
ğŸ“Š Plotting feature importance...
ğŸ” Performing SHAP analysis...

ğŸ† Best model from split 4 with RMSE: 2.6294

ğŸŒ¤ï¸  Generating 3-day AQI forecasts...
ğŸ”® Generating 3-day AQI forecast using recursive approach...
âœ… Generated 72 hourly forecasts for 3 days
ğŸ“ˆ Forecast range: 136.6 - 170.3 AQI
ğŸ“Š Forecast average: 157.0 AQI

ğŸ“Š Forecast Summary:
========================================
Forecast period: 2025-12-10 22:00:00+00:00 to 2025-12-13 21:00:00+00:00
Forecast range: 136.6 - 170.3 AQI
Average forecast: 157.0 AQI
ğŸ’¾ Saving model and results...
âœ… Forecasts saved to lgbm_additional/12_11_2025_0233_pkt/aqi_3_day_forecast.csv
âœ… Model and results saved successfully to lgbm_additional/12_11_2025_0233_pkt

ğŸ“Š Overall Cross-Validation Results:
==================================================
MAE                 : 4.0711 (avg)
RMSE                : 9.2983 (avg)
R2                  : 0.9701 (avg)
MAPE                : 0.0325 (avg)
Explained Variance  : 0.9715 (avg)

ğŸ‰ Training pipeline completed successfully!

âœ… LightGBM training completed successfully!
   Result: None

============================================================
ğŸš€ Training XGBoost Model
â° Started at: 2025-12-11 02:33:15 PKT
============================================================
ğŸš€ Starting AQI XGBoost Training Pipeline...
============================================================
ğŸ“ Output directory: xgboost_additional/12_11_2025_0233_pkt

ğŸ“Š Step 1: Fetching data from Hopsworks...
ğŸ“ Attempting to load data from RandomForest CSV first...
âŒ No RandomForest CSV files found, trying general CSV files...
ğŸ”— Connecting to Hopsworks project: anassale
2025-12-11 02:33:15,097 INFO: Closing external client and cleaning up certificates.
Connection closed.
2025-12-11 02:33:15,100 INFO: Initializing external client
2025-12-11 02:33:15,100 INFO: Base URL: https://c.app.hopsworks.ai:443
2025-12-11 02:33:15,755 INFO: Python Engine initialized.

Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1263764
âœ… Successfully connected to Hopsworks
âœ… Latest version of karachifeatures10: 1
ğŸ“¥ Retrieving features from: karachifeatures10 (v1)
ğŸ“‹ Retrieving all records...
Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.76s) 
ğŸ”„ Sorting data by datetime for chronological order...
âœ… Successfully retrieved 10116 records
ğŸ“Š Shape: (10116, 25)

ğŸ”§ Step 2: Preprocessing data...
ğŸ”§ Preprocessing data...
   ğŸ§¹ Handling missing values...
   ğŸ“Š Ensuring engineered features are properly calculated...
   â• Creating lag features for pollutants...
   â• Creating lag features for pm2_5_nowcast...
   â• Creating lag features for pm10_nowcast...
   â• Creating lag features for co_ppm_8hr_avg...
   â• Creating lag features for no2_ppb...
   âœ… After preprocessing: 10111 records

ğŸ“Š Step 3: Creating time series splits...
ğŸ“Š Creating time series splits...
âš ï¸ Skipping split - insufficient training data: 1 samples
âœ… Created 4 time series splits

ğŸ¤– Step 4: Training XGBoost models...

ğŸ“ˆ Training split 1/4...
ğŸ¤– Training XGBoost model...
âœ… Using optimized hyperparameters from Optuna
ğŸ¯ Key params: max_depth=8, learning_rate=0.050, n_estimators=1500
[0]	validation_0-rmse:63.17122
[100]	validation_0-rmse:3.70603
[200]	validation_0-rmse:3.62669
[300]	validation_0-rmse:3.62593
[400]	validation_0-rmse:3.62556
[500]	validation_0-rmse:3.62532
[600]	validation_0-rmse:3.62531
[700]	validation_0-rmse:3.62522
[800]	validation_0-rmse:3.62518
[900]	validation_0-rmse:3.62517
[1000]	validation_0-rmse:3.62517
[1100]	validation_0-rmse:3.62516
[1200]	validation_0-rmse:3.62516
[1300]	validation_0-rmse:3.62516
[1400]	validation_0-rmse:3.62516
[1499]	validation_0-rmse:3.62516
âœ… Model trained successfully
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 9.8941
RMSE                : 26.1478
R2                  : 0.9115
MAPE                : 0.0314
Explained Variance  : 0.9170

ğŸ“ˆ Training split 2/4...
ğŸ¤– Training XGBoost model...
âœ… Using optimized hyperparameters from Optuna
ğŸ¯ Key params: max_depth=8, learning_rate=0.050, n_estimators=1500
[0]	validation_0-rmse:118.77959
[100]	validation_0-rmse:3.71127
[200]	validation_0-rmse:3.43761
[300]	validation_0-rmse:3.43361
[400]	validation_0-rmse:3.43319
[500]	validation_0-rmse:3.43219
[600]	validation_0-rmse:3.43190
[700]	validation_0-rmse:3.43178
[800]	validation_0-rmse:3.43164
[900]	validation_0-rmse:3.43157
[1000]	validation_0-rmse:3.43144
[1100]	validation_0-rmse:3.43141
[1200]	validation_0-rmse:3.43138
[1300]	validation_0-rmse:3.43136
[1400]	validation_0-rmse:3.43135
[1499]	validation_0-rmse:3.43134
âœ… Model trained successfully
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 2.6603
RMSE                : 4.5692
R2                  : 0.9972
MAPE                : 0.0345
Explained Variance  : 0.9973

ğŸ“ˆ Training split 3/4...
ğŸ¤– Training XGBoost model...
âœ… Using optimized hyperparameters from Optuna
ğŸ¯ Key params: max_depth=8, learning_rate=0.050, n_estimators=1500
[0]	validation_0-rmse:83.53285
[100]	validation_0-rmse:4.53110
[200]	validation_0-rmse:4.29043
[300]	validation_0-rmse:4.26753
[400]	validation_0-rmse:4.26325
[500]	validation_0-rmse:4.25606
[600]	validation_0-rmse:4.25007
[700]	validation_0-rmse:4.24776
[800]	validation_0-rmse:4.24152
[900]	validation_0-rmse:4.24103
[1000]	validation_0-rmse:4.24056
[1100]	validation_0-rmse:4.24038
[1200]	validation_0-rmse:4.23987
[1300]	validation_0-rmse:4.24010
[1400]	validation_0-rmse:4.23989
[1499]	validation_0-rmse:4.24001
âœ… Model trained successfully
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 1.8771
RMSE                : 3.0176
R2                  : 0.9836
MAPE                : 0.0354
Explained Variance  : 0.9851

ğŸ“ˆ Training split 4/4...
ğŸ¤– Training XGBoost model...
âœ… Using optimized hyperparameters from Optuna
ğŸ¯ Key params: max_depth=8, learning_rate=0.050, n_estimators=1500
[0]	validation_0-rmse:77.61283
[100]	validation_0-rmse:1.35207
[200]	validation_0-rmse:1.27263
[300]	validation_0-rmse:1.27235
[400]	validation_0-rmse:1.27119
[500]	validation_0-rmse:1.27219
[600]	validation_0-rmse:1.27323
[700]	validation_0-rmse:1.27403
[800]	validation_0-rmse:1.27466
[900]	validation_0-rmse:1.27467
[1000]	validation_0-rmse:1.27480
[1100]	validation_0-rmse:1.27472
[1200]	validation_0-rmse:1.27475
[1300]	validation_0-rmse:1.27485
[1400]	validation_0-rmse:1.27483
[1499]	validation_0-rmse:1.27483
Traceback (most recent call last):
  File "/home/runner/work/aqi-predictor-10-pearls/aqi-predictor-10-pearls/aqi_xgboost_training_pipeline.py", line 896, in main
    best_model.save_model(model_path)
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/xgboost/sklearn.py", line 1113, in save_model
    meta["_estimator_type"] = self._get_type()
                              ^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/xgboost/sklearn.py", line 1104, in _get_type
    raise TypeError(
TypeError: `_estimator_type` undefined.  Please use appropriate mixin to define estimator type.
âœ… Model trained successfully
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 1.0269
RMSE                : 2.4760
R2                  : 0.9979
MAPE                : 0.0274
Explained Variance  : 0.9979

ğŸ† Best model from split 4
ğŸ“Š Best metrics:
   MAE: 1.0269
   RMSE: 2.4760
   R2: 0.9979
   MAPE: 0.0274
   Explained Variance: 0.9979

ğŸ“Š Step 5: Feature importance analysis...
ğŸ“Š Plotting feature importance...

ğŸ” Step 6: Model interpretability analysis...
ğŸ” Performing SHAP analysis...
ğŸ” Performing LIME analysis (fast mode)...

ğŸ”® Step 7: Generating 3-day AQI forecasts...
ğŸ”® Generating 3-day AQI forecast using recursive approach...
   ğŸ“… Forecasting for 2025-12-10 22:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-10 23:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 00:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 01:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 02:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 03:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 04:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 05:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 06:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 07:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 08:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 09:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 10:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 11:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 12:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 13:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 14:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 15:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 16:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 17:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 18:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 19:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 20:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 21:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 22:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-11 23:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 00:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 01:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 02:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 03:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 04:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 05:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 06:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 07:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 08:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 09:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 10:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 11:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 12:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 13:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 14:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 15:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 16:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 17:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 18:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 19:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 20:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 21:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 22:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-12 23:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 00:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 01:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 02:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 03:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 04:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 05:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 06:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 07:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 08:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 09:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 10:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 11:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 12:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 13:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 14:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 15:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 16:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 17:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 18:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 19:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 20:00:00+00:00...
   ğŸ“… Forecasting for 2025-12-13 21:00:00+00:00...
âœ… Generated 72 hourly forecasts for 3 days
ï¿½ Forecast range: 138.2 - 158.0 AQI
ğŸ“Š Forecast average: 153.0 AQI

ğŸ’¾ Step 8: Saving results...

âŒ Error in training pipeline: `_estimator_type` undefined.  Please use appropriate mixin to define estimator type.

âœ… XGBoost training completed successfully!
   Result: (None, None, None)

======================================================================
ğŸ“Š TRAINING SUMMARY
======================================================================
â° Completed at: 2025-12-11 02:34:13 PKT
âœ… Successful: 3/3 models
   âœ… RandomForest
   âœ… LightGBM
   âœ… XGBoost

ğŸ‰ All models trained successfully!
2025-12-11 02:34:13,090 INFO: Closing external client and cleaning up certificates.
Connection closed.
