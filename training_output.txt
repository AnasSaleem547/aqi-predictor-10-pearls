ğŸ¯ Unified AQI Model Training Pipeline
ğŸ• Pipeline started at: 2025-11-27 02:23:34 PKT
======================================================================

============================================================
ğŸš€ Training RandomForest Model
â° Started at: 2025-11-27 02:23:37 PKT
============================================================
ğŸš€ Starting AQI Random Forest Training Pipeline...
============================================================
ğŸ“ Output directory: randomforest_additional/11_27_2025_0223_pkt

ğŸ“Š Step 1: Fetching data from Hopsworks...
ğŸ”— Connecting to Hopsworks project: anassale
2025-11-27 02:23:37,664 INFO: Initializing external client
2025-11-27 02:23:37,664 INFO: Base URL: https://c.app.hopsworks.ai:443
2025-11-27 02:23:38,892 INFO: Python Engine initialized.

Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1263764
âœ… Successfully connected to Hopsworks
âœ… Latest version of karachifeatures10: 1
ğŸ“¥ Retrieving features from: karachifeatures10 (v1)
ğŸ“‹ Retrieving all records...
Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.07s) 
ğŸ”„ Sorting data by datetime for chronological order...
âœ… Successfully retrieved 9784 records
ğŸ“Š Shape: (9784, 25)

ğŸ”§ Step 2: Preprocessing data...
ğŸ”§ Preprocessing data...
   ğŸ§¹ Handling missing values...
   ğŸ“Š Ensuring engineered features are properly calculated...
   â• Creating lag features for pollutants...
   â• Creating lag features for pm2_5_nowcast...
   â• Creating lag features for pm10_nowcast...
   â• Creating lag features for co_ppm_8hr_avg...
   â• Creating lag features for no2_ppb...
   âœ… After preprocessing: 9779 records

ğŸ“Š Step 3: Creating time series splits...
ğŸ“Š Creating time series splits...
âš ï¸ Skipping split - insufficient training data: 4 samples
âœ… Created 4 time series splits

ğŸ¤– Step 4: Training Random Forest models...

ğŸ“ Training on split 1/4
ğŸ¤– Training Random Forest model...
âœ… Using optimized hyperparameters from Optuna
ğŸ¯ Key params: n_estimators=500, max_depth=25, min_samples_split=6
âœ… Model trained successfully
ğŸ“Š Validation RMSE: 3.4575
ğŸŒ² OOB Score: 0.9978
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 8.7869
RMSE                : 28.3902
R2                  : 0.8947
MAPE                : 0.0228
Explained Variance  : 0.9001
ğŸ† New best model found! RÂ² = 0.8947

ğŸ“ Training on split 2/4
ğŸ¤– Training Random Forest model...
âœ… Using optimized hyperparameters from Optuna
ğŸ¯ Key params: n_estimators=500, max_depth=25, min_samples_split=6
âœ… Model trained successfully
ğŸ“Š Validation RMSE: 1.5417
ğŸŒ² OOB Score: 0.9993
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 1.4552
RMSE                : 3.1713
R2                  : 0.9988
MAPE                : 0.0222
Explained Variance  : 0.9989
ğŸ† New best model found! RÂ² = 0.9988

ğŸ“ Training on split 3/4
ğŸ¤– Training Random Forest model...
âœ… Using optimized hyperparameters from Optuna
ğŸ¯ Key params: n_estimators=500, max_depth=25, min_samples_split=6
âœ… Model trained successfully
ğŸ“Š Validation RMSE: 3.4415
ğŸŒ² OOB Score: 0.9997
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 1.7263
RMSE                : 3.3197
R2                  : 0.9771
MAPE                : 0.0207
Explained Variance  : 0.9790

ğŸ“ Training on split 4/4
ğŸ¤– Training Random Forest model...
âœ… Using optimized hyperparameters from Optuna
ğŸ¯ Key params: n_estimators=500, max_depth=25, min_samples_split=6
âœ… Model trained successfully
ğŸ“Š Validation RMSE: 0.9159
ğŸŒ² OOB Score: 0.9997
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 0.5541
RMSE                : 2.0470
R2                  : 0.9985
MAPE                : 0.0216
Explained Variance  : 0.9986

ğŸ“Š Step 5: Analyzing feature importance (best model from split 2)...
ğŸ“Š Plotting feature importance...

ğŸ” Step 6: SHAP analysis...
ğŸ” Performing SHAP analysis...

ğŸ” Step 7: LIME analysis...
ğŸ” Performing LIME analysis (fast mode)...

ğŸ”® Step 8: Generating 3-day AQI forecast...
ğŸ”® Generating 3-day AQI forecast using recursive approach...
ğŸ“Š Starting forecast from: 2025-11-26 21:00:00+00:00
ğŸ¯ Forecasting 72 hours ahead...
âœ… Generated 72 hourly forecasts for 3 days
ğŸ“Š Forecast range: 166.0 - 269.0 AQI
ğŸ“ˆ Forecast average: 190.1 AQI

ğŸ”§ Step 8b: Applying bias correction...
âœ… Loaded XGBoost forecasts from 11_25_2025_0227_pkt
âœ… Loaded LightGBM forecasts from 11_25_2025_0227_pkt
ğŸ“Š Reference mean from 2 models: 165.33
ğŸ“ˆ Random Forest forecast mean: 190.15
ğŸ“Š Reference mean: 165.33
ğŸ“Š Ratio (RF/Reference): 1.15
âœ… No bias correction needed

ğŸ’¾ Step 9: Saving results...

âœ… Random Forest Training Pipeline Completed Successfully!
============================================================
ğŸ“ All results saved to: randomforest_additional/11_27_2025_0223_pkt
ğŸ¯ Best RÂ² Score: 0.9988
ğŸ“Š Best MAE: 1.4552
ğŸ“ˆ Best MAPE: 0.0222

âœ… RandomForest training completed successfully!
   Result: (RandomForestRegressor(max_depth=25, max_features=None, min_samples_leaf=2,
                      min_samples_split=6, n_estimators=500, n_jobs=-1,
                      oob_score=True, random_state=42), {'MAE': 1.455242486695219, 'RMSE': 3.171253387331068, 'R2': 0.9988383267660267, 'MAPE': 0.022205351596739586, 'Explained Variance': 0.998872782307943}, 'randomforest_additional/11_27_2025_0223_pkt')

============================================================
ğŸš€ Training LightGBM Model
â° Started at: 2025-11-27 02:24:27 PKT
============================================================
ğŸš€ Starting AQI LGBM Training Pipeline
============================================================
ğŸ“ Attempting to load data from RandomForest CSV first...
âŒ No RandomForest CSV files found, trying general CSV files...
ğŸ”— Connecting to Hopsworks project: anassale
2025-11-27 02:24:27,852 INFO: Closing external client and cleaning up certificates.
Connection closed.
2025-11-27 02:24:27,855 INFO: Initializing external client
2025-11-27 02:24:27,855 INFO: Base URL: https://c.app.hopsworks.ai:443
2025-11-27 02:24:28,849 INFO: Python Engine initialized.

Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1263764
âœ… Successfully connected to Hopsworks
âœ… Latest version of karachifeatures10: 1
ğŸ“¥ Retrieving features from: karachifeatures10 (v1)
ğŸ“‹ Retrieving all records...
Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   Reading data from Hopsworks, using Hopsworks Feature Query Service   Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Reading data from Hopsworks, using Hopsworks Feature Query Service...   2025-11-27 02:25:13,021 ERROR: [Errno 255] Opening HDFS file '/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties' failed. Detail: [errno 255] Unknown error 255. Detail: Python exception: Traceback (most recent call last):
  File "/usr/src/app/src/server.py", line 142, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 166, in wrapper
    result = func(instance, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 196, in do_get
    return self._read_query(context, path, command)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 123, in wrapper
    return func(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 131, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 227, in _read_query
    result_batches = self.hudi_query_engine.read_query(query_obj)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/hudi_query_engine.py", line 63, in read_query
    hudi_featuregroups_paths[full_featuregroup_name] = self.hudi_hops_client.get_featuregroup_parquet_paths(
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/hudi_hopsfs_client.py", line 55, in get_featuregroup_parquet_paths
    partition_keys = self._get_partition_keys_from_metadata(featuregroup_absolute_path)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/hudi_hopsfs_client.py", line 185, in _get_partition_keys_from_metadata
    with self.hopsfs.open(featuregroup_hoodie_properties_path.as_posix(), "rt") as f:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/fsspec/spec.py", line 1139, in open
    self.open(
  File "/opt/venv/lib/python3.11/site-packages/fsspec/spec.py", line 1151, in open
    f = self._open(
        ^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/fsspec/implementations/arrow.py", line 22, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/fsspec/implementations/arrow.py", line 178, in _open
    stream = method(path, **_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "pyarrow/_fs.pyx", line 789, in pyarrow._fs.FileSystem.open_input_file
  File "pyarrow/error.pxi", line 155, in pyarrow.lib.pyarrow_internal_check_status
  File "pyarrow/error.pxi", line 92, in pyarrow.lib.check_status
OSError: [Errno 255] Opening HDFS file '/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties' failed. Detail: [errno 255] Unknown error 255

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "pyarrow/_flight.pyx", line 2255, in pyarrow._flight._do_get
  File "/usr/src/app/src/server.py", line 145, in wrapper
    raise FlyingDuckException(str(e)) from e
utils.exceptions.FlyingDuckException: [Errno 255] Opening HDFS file '/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties' failed. Detail: [errno 255] Unknown error 255
. gRPC client debug context: UNKNOWN:Error received from peer ipv4:51.79.26.27:5005 {created_time:"2025-11-27T02:25:13.020701934+05:00", grpc_status:2, grpc_message:"[Errno 255] Opening HDFS file \'/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties\' failed. Detail: [errno 255] Unknown error 255. Detail: Python exception: Traceback (most recent call last):\n  File \"/usr/src/app/src/server.py\", line 142, in wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 166, in wrapper\n    result = func(instance, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 196, in do_get\n    return self._read_query(context, path, command)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 123, in wrapper\n    return func(instance, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 131, in wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 227, in _read_query\n    result_batches = self.hudi_query_engine.read_query(query_obj)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/hudi_query_engine.py\", line 63, in read_query\n    hudi_featuregroups_paths[full_featuregroup_name] = self.hudi_hops_client.get_featuregroup_parquet_paths(\n                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/hudi_hopsfs_client.py\", line 55, in get_featuregroup_parquet_paths\n    partition_keys = self._get_partition_keys_from_metadata(featuregroup_absolute_path)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/hudi_hopsfs_client.py\", line 185, in _get_partition_keys_from_metadata\n    with self.hopsfs.open(featuregroup_hoodie_properties_path.as_posix(), \"rt\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/venv/lib/python3.11/site-packages/fsspec/spec.py\", line 1139, in open\n    self.open(\n  File \"/opt/venv/lib/python3.11/site-packages/fsspec/spec.py\", line 1151, in open\n    f = self._open(\n        ^^^^^^^^^^^\n  File \"/opt/venv/lib/python3.11/site-packages/fsspec/implementations/arrow.py\", line 22, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/venv/lib/python3.11/site-packages/fsspec/implementations/arrow.py\", line 178, in _open\n    stream = method(path, **_kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"pyarrow/_fs.pyx\", line 789, in pyarrow._fs.FileSystem.open_input_file\n  File \"pyarrow/error.pxi\", line 155, in pyarrow.lib.pyarrow_internal_check_status\n  File \"pyarrow/error.pxi\", line 92, in pyarrow.lib.check_status\nOSError: [Errno 255] Opening HDFS file \'/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties\' failed. Detail: [errno 255] Unknown error 255\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"pyarrow/_flight.pyx\", line 2255, in pyarrow._flight._do_get\n  File \"/usr/src/app/src/server.py\", line 145, in wrapper\n    raise FlyingDuckException(str(e)) from e\nutils.exceptions.FlyingDuckException: [Errno 255] Opening HDFS file \'/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties\' failed. Detail: [errno 255] Unknown error 255\n"}. Client context: IOError: Server never sent a data message. Detail: Internal
Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/hsfs/core/arrow_flight_client.py", line 394, in afs_error_handler_wrapper
    return func(instance, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/hsfs/core/arrow_flight_client.py", line 459, in read_query
    return self._get_dataset(
           ^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/retrying.py", line 55, in wrapped_f
    return Retrying(*dargs, **dkw).call(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/retrying.py", line 279, in call
    return attempt.get(self._wrap_exception)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/retrying.py", line 326, in get
    raise exc.with_traceback(tb)
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/retrying.py", line 273, in call
    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)
                      ^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/hsfs/core/arrow_flight_client.py", line 445, in _get_dataset
    reader = self._connection.do_get(info.endpoints[0].ticket, options)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "pyarrow/_flight.pyx", line 1701, in pyarrow._flight.FlightClient.do_get
  File "pyarrow/_flight.pyx", line 58, in pyarrow._flight.check_flight_status
pyarrow._flight.FlightServerError: [Errno 255] Opening HDFS file '/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties' failed. Detail: [errno 255] Unknown error 255. Detail: Python exception: Traceback (most recent call last):
  File "/usr/src/app/src/server.py", line 142, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 166, in wrapper
    result = func(instance, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 196, in do_get
    return self._read_query(context, path, command)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 123, in wrapper
    return func(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 131, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/server.py", line 227, in _read_query
    result_batches = self.hudi_query_engine.read_query(query_obj)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/hudi_query_engine.py", line 63, in read_query
    hudi_featuregroups_paths[full_featuregroup_name] = self.hudi_hops_client.get_featuregroup_parquet_paths(
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/hudi_hopsfs_client.py", line 55, in get_featuregroup_parquet_paths
    partition_keys = self._get_partition_keys_from_metadata(featuregroup_absolute_path)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/src/app/src/hudi_hopsfs_client.py", line 185, in _get_partition_keys_from_metadata
    with self.hopsfs.open(featuregroup_hoodie_properties_path.as_posix(), "rt") as f:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/fsspec/spec.py", line 1139, in open
    self.open(
  File "/opt/venv/lib/python3.11/site-packages/fsspec/spec.py", line 1151, in open
    f = self._open(
        ^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/fsspec/implementations/arrow.py", line 22, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/fsspec/implementations/arrow.py", line 178, in _open
    stream = method(path, **_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "pyarrow/_fs.pyx", line 789, in pyarrow._fs.FileSystem.open_input_file
  File "pyarrow/error.pxi", line 155, in pyarrow.lib.pyarrow_internal_check_status
  File "pyarrow/error.pxi", line 92, in pyarrow.lib.check_status
OSError: [Errno 255] Opening HDFS file '/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties' failed. Detail: [errno 255] Unknown error 255

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "pyarrow/_flight.pyx", line 2255, in pyarrow._flight._do_get
  File "/usr/src/app/src/server.py", line 145, in wrapper
    raise FlyingDuckException(str(e)) from e
utils.exceptions.FlyingDuckException: [Errno 255] Opening HDFS file '/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties' failed. Detail: [errno 255] Unknown error 255
. gRPC client debug context: UNKNOWN:Error received from peer ipv4:51.79.26.27:5005 {created_time:"2025-11-27T02:25:13.020701934+05:00", grpc_status:2, grpc_message:"[Errno 255] Opening HDFS file \'/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties\' failed. Detail: [errno 255] Unknown error 255. Detail: Python exception: Traceback (most recent call last):\n  File \"/usr/src/app/src/server.py\", line 142, in wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 166, in wrapper\n    result = func(instance, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 196, in do_get\n    return self._read_query(context, path, command)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 123, in wrapper\n    return func(instance, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 131, in wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/server.py\", line 227, in _read_query\n    result_batches = self.hudi_query_engine.read_query(query_obj)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/hudi_query_engine.py\", line 63, in read_query\n    hudi_featuregroups_paths[full_featuregroup_name] = self.hudi_hops_client.get_featuregroup_parquet_paths(\n                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/hudi_hopsfs_client.py\", line 55, in get_featuregroup_parquet_paths\n    partition_keys = self._get_partition_keys_from_metadata(featuregroup_absolute_path)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/src/app/src/hudi_hopsfs_client.py\", line 185, in _get_partition_keys_from_metadata\n    with self.hopsfs.open(featuregroup_hoodie_properties_path.as_posix(), \"rt\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/venv/lib/python3.11/site-packages/fsspec/spec.py\", line 1139, in open\n    self.open(\n  File \"/opt/venv/lib/python3.11/site-packages/fsspec/spec.py\", line 1151, in open\n    f = self._open(\n        ^^^^^^^^^^^\n  File \"/opt/venv/lib/python3.11/site-packages/fsspec/implementations/arrow.py\", line 22, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/venv/lib/python3.11/site-packages/fsspec/implementations/arrow.py\", line 178, in _open\n    stream = method(path, **_kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"pyarrow/_fs.pyx\", line 789, in pyarrow._fs.FileSystem.open_input_file\n  File \"pyarrow/error.pxi\", line 155, in pyarrow.lib.pyarrow_internal_check_status\n  File \"pyarrow/error.pxi\", line 92, in pyarrow.lib.check_status\nOSError: [Errno 255] Opening HDFS file \'/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties\' failed. Detail: [errno 255] Unknown error 255\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"pyarrow/_flight.pyx\", line 2255, in pyarrow._flight._do_get\n  File \"/usr/src/app/src/server.py\", line 145, in wrapper\n    raise FlyingDuckException(str(e)) from e\nutils.exceptions.FlyingDuckException: [Errno 255] Opening HDFS file \'/apps/hive/warehouse/anassale_featurestore.db/karachifeatures10_1/.hoodie/hoodie.properties\' failed. Detail: [errno 255] Unknown error 255\n"}. Client context: IOError: Server never sent a data message. Detail: Internal
Error: Reading data from Hopsworks, using Hopsworks Feature Query Service           
âŒ Failed to retrieve features from Hopsworks: Could not read data using Hopsworks Query Service.
âš ï¸ Trying local CSV files...
ğŸ“ Loading data from local file: retrieved_karachi_aqi_features15.csv
âœ… Loaded 9704 records from retrieved_karachi_aqi_features15.csv
ğŸ”§ Preprocessing data...
   ğŸ§¹ Handling missing values...
   ğŸ“Š Ensuring engineered features are properly calculated...
   â• Creating lag features for pollutants...
   â• Creating lag features for pm2_5_nowcast...
   â• Creating lag features for pm10_nowcast...
   â• Creating lag features for co_ppm_8hr_avg...
   â• Creating lag features for no2_ppb...
   âœ… After preprocessing: 9699 records
ğŸ“Š Final dataset shape: (9699, 22)
ğŸ¯ Target variable range: 9.0 - 500.0
ğŸ“Š Creating time series splits...
âš ï¸ Skipping split - insufficient training data: 4 samples
âœ… Created 4 time series splits

ğŸ” Processing split 1/4
----------------------------------------
   Train: 1555 samples
   Val:   388 samples
   Test:  1939 samples
ğŸ¤– Training LightGBM model...
âœ… Using optimized hyperparameters
Training until validation scores don't improve for 50 rounds
[100]	valid_0's l2: 44.9789
Early stopping, best iteration is:
[56]	valid_0's l2: 43.5622
âœ… Model trained with 56 iterations
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 13.5400
RMSE                : 34.4504
R2                  : 0.8454
MAPE                : 0.0417
Explained Variance  : 0.8579
ğŸ“Š Plotting feature importance...
ğŸ” Performing SHAP analysis...
ğŸ” Performing LIME analysis...
Intercept 64.11116504286281
Prediction_local [161.31660424]
Right: 155.71858082848888

ğŸ” Processing split 2/4
----------------------------------------
   Train: 3106 samples
   Val:   776 samples
   Test:  1939 samples
ğŸ¤– Training LightGBM model...
âœ… Using optimized hyperparameters
Training until validation scores don't improve for 50 rounds
[100]	valid_0's l2: 19.6157
Early stopping, best iteration is:
[109]	valid_0's l2: 19.5125
âœ… Model trained with 109 iterations
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 2.3739
RMSE                : 4.2786
R2                  : 0.9979
MAPE                : 0.0292
Explained Variance  : 0.9979
ğŸ“Š Plotting feature importance...
ğŸ” Performing SHAP analysis...

ğŸ” Processing split 3/4
----------------------------------------
   Train: 4657 samples
   Val:   1164 samples
   Test:  1939 samples
ğŸ¤– Training LightGBM model...
âœ… Using optimized hyperparameters
Training until validation scores don't improve for 50 rounds
[100]	valid_0's l2: 13.7992
[200]	valid_0's l2: 13.0689
Early stopping, best iteration is:
[206]	valid_0's l2: 12.9779
âœ… Model trained with 206 iterations
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 1.6232
RMSE                : 2.5693
R2                  : 0.9865
MAPE                : 0.0237
Explained Variance  : 0.9875
ğŸ“Š Plotting feature importance...
ğŸ” Performing SHAP analysis...

ğŸ” Processing split 4/4
----------------------------------------
   Train: 6208 samples
   Val:   1552 samples
   Test:  1939 samples
ğŸ¤– Training LightGBM model...
âœ… Using optimized hyperparameters
Training until validation scores don't improve for 50 rounds
[100]	valid_0's l2: 2.58619
[200]	valid_0's l2: 2.53265
Early stopping, best iteration is:
[212]	valid_0's l2: 2.51774
âœ… Model trained with 212 iterations
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 1.1765
RMSE                : 2.6242
R2                  : 0.9973
MAPE                : 0.0360
Explained Variance  : 0.9973
ğŸ“Š Plotting feature importance...
ğŸ” Performing SHAP analysis...

ğŸ† Best model from split 3 with RMSE: 2.5693

ğŸŒ¤ï¸  Generating 3-day AQI forecasts...
ğŸ”® Generating 3-day AQI forecast using recursive approach...
âœ… Generated 72 hourly forecasts for 3 days
ğŸ“ˆ Forecast range: 159.5 - 191.8 AQI
ğŸ“Š Forecast average: 174.0 AQI

ğŸ“Š Forecast Summary:
========================================
Forecast period: 2025-11-23 18:00:00 to 2025-11-26 17:00:00
Forecast range: 159.5 - 191.8 AQI
Average forecast: 174.0 AQI
ğŸ’¾ Saving model and results...
âœ… Forecasts saved to lgbm_additional/11_27_2025_0225_pkt/aqi_3_day_forecast.csv
âœ… Model and results saved successfully to lgbm_additional/11_27_2025_0225_pkt

ğŸ“Š Overall Cross-Validation Results:
==================================================
MAE                 : 4.6784 (avg)
RMSE                : 10.9806 (avg)
R2                  : 0.9568 (avg)
MAPE                : 0.0327 (avg)
Explained Variance  : 0.9602 (avg)

ğŸ‰ Training pipeline completed successfully!

âœ… LightGBM training completed successfully!
   Result: None

============================================================
ğŸš€ Training XGBoost Model
â° Started at: 2025-11-27 02:25:31 PKT
============================================================
ğŸš€ Starting AQI XGBoost Training Pipeline...
============================================================
ğŸ“ Output directory: xgboost_additional/11_27_2025_0225_pkt

ğŸ“Š Step 1: Fetching data from Hopsworks...
ğŸ“ Attempting to load data from RandomForest CSV first...
âŒ No RandomForest CSV files found, trying general CSV files...
ğŸ”— Connecting to Hopsworks project: anassale
2025-11-27 02:25:31,364 INFO: Closing external client and cleaning up certificates.
Connection closed.
2025-11-27 02:25:31,366 INFO: Initializing external client
2025-11-27 02:25:31,366 INFO: Base URL: https://c.app.hopsworks.ai:443
2025-11-27 02:25:32,322 INFO: Python Engine initialized.

Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1263764
âœ… Successfully connected to Hopsworks
âœ… Latest version of karachifeatures10: 1
ğŸ“¥ Retrieving features from: karachifeatures10 (v1)
ğŸ“‹ Retrieving all records...
Reading data from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service..   Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.00s) 
ğŸ”„ Sorting data by datetime for chronological order...
âœ… Successfully retrieved 9784 records
ğŸ“Š Shape: (9784, 25)

ğŸ”§ Step 2: Preprocessing data...
ğŸ”§ Preprocessing data...
   ğŸ§¹ Handling missing values...
   ğŸ“Š Ensuring engineered features are properly calculated...
   â• Creating lag features for pollutants...
   â• Creating lag features for pm2_5_nowcast...
   â• Creating lag features for pm10_nowcast...
   â• Creating lag features for co_ppm_8hr_avg...
   â• Creating lag features for no2_ppb...
   âœ… After preprocessing: 9779 records

ğŸ“Š Step 3: Creating time series splits...
ğŸ“Š Creating time series splits...
âš ï¸ Skipping split - insufficient training data: 4 samples
âœ… Created 4 time series splits

ğŸ¤– Step 4: Training XGBoost models...

ğŸ“ˆ Training split 1/4...
ğŸ¤– Training XGBoost model...
âœ… Using optimized hyperparameters from Optuna
ğŸ¯ Key params: max_depth=8, learning_rate=0.050, n_estimators=1500
[0]	validation_0-rmse:66.86308
[100]	validation_0-rmse:4.50723
[200]	validation_0-rmse:4.49417
[300]	validation_0-rmse:4.49291
[400]	validation_0-rmse:4.49239
[500]	validation_0-rmse:4.49200
[600]	validation_0-rmse:4.49172
[700]	validation_0-rmse:4.49169
[800]	validation_0-rmse:4.49166
[900]	validation_0-rmse:4.49164
[1000]	validation_0-rmse:4.49165
[1100]	validation_0-rmse:4.49163
[1200]	validation_0-rmse:4.49162
[1300]	validation_0-rmse:4.49162
[1400]	validation_0-rmse:4.49162
[1499]	validation_0-rmse:4.49161
âœ… Model trained successfully
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 10.1611
RMSE                : 27.0778
R2                  : 0.9042
MAPE                : 0.0314
Explained Variance  : 0.9106

ğŸ“ˆ Training split 2/4...
ğŸ¤– Training XGBoost model...
âœ… Using optimized hyperparameters from Optuna
ğŸ¯ Key params: max_depth=8, learning_rate=0.050, n_estimators=1500
[0]	validation_0-rmse:126.81546
[100]	validation_0-rmse:4.34390
[200]	validation_0-rmse:3.97721
[300]	validation_0-rmse:3.97433
[400]	validation_0-rmse:3.97367
[500]	validation_0-rmse:3.97361
[600]	validation_0-rmse:3.97373
[700]	validation_0-rmse:3.97339
[800]	validation_0-rmse:3.97330
[900]	validation_0-rmse:3.97337
[1000]	validation_0-rmse:3.97335
[1100]	validation_0-rmse:3.97334
[1200]	validation_0-rmse:3.97331
[1300]	validation_0-rmse:3.97331
[1400]	validation_0-rmse:3.97331
[1499]	validation_0-rmse:3.97330
âœ… Model trained successfully
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 2.5065
RMSE                : 4.7355
R2                  : 0.9974
MAPE                : 0.0308
Explained Variance  : 0.9974

ğŸ“ˆ Training split 3/4...
ğŸ¤– Training XGBoost model...
âœ… Using optimized hyperparameters from Optuna
ğŸ¯ Key params: max_depth=8, learning_rate=0.050, n_estimators=1500
[0]	validation_0-rmse:86.73062
[100]	validation_0-rmse:3.94856
[200]	validation_0-rmse:3.71673
[300]	validation_0-rmse:3.68630
[400]	validation_0-rmse:3.68633
[500]	validation_0-rmse:3.69150
[600]	validation_0-rmse:3.69671
[700]	validation_0-rmse:3.69268
[800]	validation_0-rmse:3.69570
[900]	validation_0-rmse:3.69624
[1000]	validation_0-rmse:3.69538
[1100]	validation_0-rmse:3.69573
[1200]	validation_0-rmse:3.69577
[1300]	validation_0-rmse:3.69557
[1400]	validation_0-rmse:3.69552
[1499]	validation_0-rmse:3.69554
âœ… Model trained successfully
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 2.2226
RMSE                : 3.3848
R2                  : 0.9762
MAPE                : 0.0315
Explained Variance  : 0.9796

ğŸ“ˆ Training split 4/4...
ğŸ¤– Training XGBoost model...
âœ… Using optimized hyperparameters from Optuna
ğŸ¯ Key params: max_depth=8, learning_rate=0.050, n_estimators=1500
[0]	validation_0-rmse:71.98352
[100]	validation_0-rmse:1.40559
[200]	validation_0-rmse:1.30315
[300]	validation_0-rmse:1.29931
[400]	validation_0-rmse:1.30079
[500]	validation_0-rmse:1.29959
[600]	validation_0-rmse:1.30054
[700]	validation_0-rmse:1.29939
[800]	validation_0-rmse:1.29942
[900]	validation_0-rmse:1.29919
[1000]	validation_0-rmse:1.29908
[1100]	validation_0-rmse:1.29897
[1200]	validation_0-rmse:1.29903
[1300]	validation_0-rmse:1.29902
[1400]	validation_0-rmse:1.29915
[1499]	validation_0-rmse:1.29907
âœ… Model trained successfully
ğŸ“Š Evaluating model performance...

ğŸ“ˆ Model Performance Metrics:
==================================================
MAE                 : 0.9782
RMSE                : 2.4154
R2                  : 0.9979
MAPE                : 0.0307
Explained Variance  : 0.9979

ğŸ† Best model from split 4
ğŸ“Š Best metrics:
   MAE: 0.9782
   RMSE: 2.4154
   R2: 0.9979
   MAPE: 0.0307
   Explained Variance: 0.9979

ğŸ“Š Step 5: Feature importance analysis...
ğŸ“Š Plotting feature importance...

ğŸ” Step 6: Model interpretability analysis...
ğŸ” Performing SHAP analysis...
ğŸ” Performing LIME analysis (fast mode)...

ğŸ”® Step 7: Generating 3-day AQI forecasts...
ğŸ”® Generating 3-day AQI forecast using recursive approach...
   ğŸ“… Forecasting for 2025-11-26 22:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-26 23:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 00:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 01:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 02:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 03:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 04:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 05:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 06:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 07:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 08:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 09:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 10:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 11:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 12:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 13:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 14:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 15:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 16:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 17:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 18:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 19:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 20:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 21:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 22:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-27 23:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 00:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 01:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 02:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 03:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 04:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 05:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 06:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 07:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 08:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 09:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 10:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 11:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 12:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 13:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 14:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 15:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 16:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 17:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 18:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 19:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 20:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 21:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 22:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-28 23:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 00:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 01:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 02:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 03:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 04:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 05:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 06:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 07:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 08:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 09:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 10:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 11:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 12:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 13:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 14:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 15:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 16:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 17:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 18:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 19:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 20:00:00+00:00...
   ğŸ“… Forecasting for 2025-11-29 21:00:00+00:00...
âœ… Generated 72 hourly forecasts for 3 days
ï¿½ Forecast range: 127.5 - 154.2 AQI
ğŸ“Š Forecast average: 146.7 AQI

ğŸ’¾ Step 8: Saving results...

âœ… XGBoost Training Pipeline Completed Successfully!
============================================================
ğŸ“ All results saved to: xgboost_additional/11_27_2025_0225_pkt
ğŸ¯ Best RÂ² Score: 0.9979
ğŸ“Š Best MAE: 0.9782
ğŸ“ˆ Best MAPE: 0.0307

âœ… XGBoost training completed successfully!
   Result: (XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.85, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric='rmse', feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=0.05, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=1500,
             n_jobs=-1, num_parallel_tree=None, ...), {'MAE': 0.9782036542892456, 'RMSE': 2.415436979924253, 'R2': 0.9979256391525269, 'MAPE': 0.03074973076581955, 'Explained Variance': 0.9979274272918701}, 'xgboost_additional/11_27_2025_0225_pkt')

======================================================================
ğŸ“Š TRAINING SUMMARY
======================================================================
â° Completed at: 2025-11-27 02:26:28 PKT
âœ… Successful: 3/3 models
   âœ… RandomForest
   âœ… LightGBM
   âœ… XGBoost

ğŸ‰ All models trained successfully!
2025-11-27 02:26:28,318 INFO: Closing external client and cleaning up certificates.
Connection closed.
